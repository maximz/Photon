In computer science, A* (pronounced "A star" ( listen)) is a computer algorithm that is widely used in pathfinding and graph traversal, the process of plotting an efficiently traversable path between points, called nodes. Noted for its performance and accuracy, it enjoys widespread use. (However, in practical travel-routing systems, it is generally outperformed by algorithms which can pre-process the graph to attain better performance.)
Peter Hart, Nils Nilsson and Bertram Raphael of Stanford Research Institute (now SRI International) first described the algorithm in 1968. It is an extension of Edsger Dijkstra's 1959 algorithm. A* achieves better performance (with respect to time) by using heuristics.
Description.
A* uses a best-first search and finds a least-cost path from a given initial node to one goal node (out of one or more possible goals). As A* traverses the graph, it follows a path of the lowest expected total cost or distance, keeping a sorted priority queue of alternate path segments along the way.
It uses a knowledge-plus-heuristic cost function of node formula_1 (usually denoted formula_2) to determine the order in which the search visits nodes in the tree. The cost function is a sum of two functions: 
The formula_6 part of the formula_2 function must be an admissible heuristic; that is, it must not overestimate the distance to the goal. Thus, for an application like routing, formula_6 might represent the straight-line distance to the goal, since that is physically the smallest possible distance between any two points or nodes.
If the heuristic "h" satisfies the additional condition formula_10 for every edge "x, y" of the graph (where "d" denotes the length of that edge), then "h" is called monotone, or consistent. In such a case, A* can be implemented more efficiently—roughly speaking, no node needs to be processed more than once (see "closed set" below)—and A* is equivalent to running Dijkstra's algorithm with the reduced cost formula_11.
History.
In 1968 Nils Nilsson suggested a heuristic approach for Shakey the Robot to navigate through a room containing obstacles. This path-finding algorithm, called A1, was a faster version of the then best known formal approach, Dijkstra's algorithm, for finding shortest paths in graphs. Bertram Raphael suggested some significant improvements upon this algorithm, calling the revised version A2. Then Peter E. Hart introduced an argument that established A2, with only minor changes, to be the best possible algorithm for finding shortest paths. Hart, Nilsson and Raphael then jointly developed a proof that the revised A2 algorithm was "optimal" for finding shortest paths under certain well-defined conditions. They thus named the new algorithm in Kleene star syntax to be the algorithm that starts with A and includes all possible version numbers or A*.
Process.
Like all informed search algorithms, it first searches the routes that "appear" to be most likely to lead towards the goal. What sets A* apart from a greedy best-first search is that it also takes the distance already traveled into account; the formula_4 part of the heuristic is the cost from the starting point, not simply the local cost from the previously expanded node.
Starting with the initial node, it maintains a priority queue of nodes to be traversed, known as the "open set". The lower formula_2 for a given node formula_1, the higher its priority. At each step of the algorithm, the node with the lowest formula_2 value is removed from the queue, the formula_16 and formula_17 values of its neighbors are updated accordingly, and these neighbors are added to the queue. The algorithm continues until a goal node has a lower formula_16 value than any node in the queue (or until the queue is empty). (Goal nodes may be passed over multiple times if there remain other nodes with lower formula_16 values, as they may lead to a shorter path to a goal.) The formula_16 value of the goal is then the length of the shortest path, since formula_21 at the goal is zero in an admissible heuristic. 
The algorithm described so far gives us only the length of the shortest path. To find the actual sequence of steps, the algorithm can be easily revised so that each node on the path keeps track of its predecessor. After this algorithm is run, the starting node will point to its predecessor, and so on, until some node's predecessor is the goal node. 
Additionally, if the heuristic is "monotonic" (or consistent, see below), a "closed set" of nodes already traversed may be used to make the search more efficient.
Pseudocode.
</source>
Remark: the above pseudocode assumes that the heuristic function is "monotonic" (or consistent, see below), which is a frequent case in many practical problems, such as the Shortest Distance Path in road networks. However, if the assumption is not true, nodes in the closed set may be rediscovered and their cost improved. 
In other words, the closed set can be omitted (yielding a tree search algorithm) if a solution is guaranteed to exist, or if the algorithm is adapted so that new nodes are added to the open set only if they have a lower formula_16 value than at any previous iteration.
Example.
Key: green: start; blue: goal; orange: visited
Note: This example uses a comma as the decimal separator.
Properties.
Like breadth-first search, A* is "complete" and will always find a solution if one exists.
A* is also optimally efficient for any heuristic formula_21, meaning that no optimal algorithm employing the same heuristic will expand fewer nodes than A*, except when there are multiple partial solutions where formula_21 exactly predicts the cost of the optimal path. Even in this case, for each graph there exists some order of breaking ties in the priority queue such that A* examines the fewest possible nodes.
Special cases.
Dijkstra's algorithm, as another example of a uniform-cost search algorithm, can be viewed as a special case of A* where formula_42 for all formula_1. General depth-first search can be implemented using the A* by considering that there is a global counter "C" initialized with a very large value. Every time we process a node we assign "C" to all of its newly discovered neighbors. After each single assignment, we decrease the counter "C" by one. Thus the earlier a node is discovered, the higher its formula_6 value. It should be noted, however, that both Dijkstra's algorithm and depth-first search can be implemented more efficiently without including a formula_6 value at each node.
Implementation details.
There are a number of simple optimizations or implementation details that can significantly affect the performance of an A* implementation. The first detail to note is that the way the priority queue handles ties can have a significant effect on performance in some situations. If ties are broken so the queue behaves in a LIFO manner, A* will behave like depth-first search among equal cost paths. 
When a path is required at the end of the search, it is common to keep with each node a reference to that node's parent. At the end of the search these references can be used to recover the optimal path. If these references are being kept then it can be important that the same node doesn't appear in the priority queue more than once (each entry corresponding to a different path to the node, and each with a different cost). A standard approach here is to check if a node about to be added already appears in the priority queue. If it does, then the priority and parent pointers are changed to correspond to the lower cost path. When finding a node in a queue to perform this check, many standard implementations of a min-heap require formula_46 time. Augmenting the heap with a hash table can reduce this to constant time.
Admissibility and optimality.
A* is admissible and considers fewer nodes than any other admissible search algorithm with the same heuristic. This is because A* uses an "optimistic" estimate of the cost of a path through every node that it considers—optimistic in that the true cost of a path through that node to the goal will be at least as great as the estimate. But, critically, as far as A* "knows", that optimistic estimate might be achievable.
When A* terminates its search, it has found a path whose actual cost is lower than the estimated cost of any path through any open node. But since those estimates are optimistic, A* can safely ignore those nodes. In other words, A* will never overlook the possibility of a lower-cost path and so is admissible.
Suppose now that some other search algorithm B terminates its search with a path whose actual cost is "not" less than the estimated cost of a path through some open node. Based on the heuristic information it has, Algorithm B cannot rule out the possibility that a path through that node has a lower cost. So while B might consider fewer nodes than A*, it cannot be admissible. Accordingly, A* considers the fewest nodes of any admissible search algorithm.
Bounded relaxation.
While the admissibility criterion guarantees an optimal solution path, it also means that A* must examine all equally meritorious paths to find the optimal path. It is possible to speed up the search at the expense of optimality by relaxing the admissibility criterion. Oftentimes we want to bound this relaxation, so that we can guarantee that the solution path is no worse than formula_47 times the optimal solution path. This new guarantee is referred to as formula_48-admissible.
Complexity.
where formula_70 is the optimal heuristic, the exact cost to get from formula_1 to the goal. In other words, the error of "h" will not grow faster than the logarithm of the “perfect heuristic” formula_70 that returns the true distance from "x" to the goal (see Pearl 1984 and also Russell and Norvig 2003, p. 101)
